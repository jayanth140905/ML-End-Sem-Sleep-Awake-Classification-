{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b880c361-49b4-4adc-9191-f59219b9ba65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for DecisionTreeClassifier: {'max_depth': 5}\n",
      "\n",
      "Decision Tree - Feature Extracted Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.04      0.07      6607\n",
      "           1       0.82      0.99      0.90     29429\n",
      "\n",
      "    accuracy                           0.82     36036\n",
      "   macro avg       0.67      0.52      0.49     36036\n",
      "weighted avg       0.77      0.82      0.75     36036\n",
      "\n",
      "Best parameters for RandomForestClassifier: {'n_estimators': 200}\n",
      "\n",
      "Random Forest - Feature Extracted Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.19      0.25      6607\n",
      "           1       0.84      0.93      0.88     29429\n",
      "\n",
      "    accuracy                           0.79     36036\n",
      "   macro avg       0.60      0.56      0.57     36036\n",
      "weighted avg       0.75      0.79      0.76     36036\n",
      "\n",
      "Best parameters for KNeighborsClassifier: {'n_neighbors': 7}\n",
      "\n",
      "KNN - Feature Extracted Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.16      0.23      6607\n",
      "           1       0.83      0.94      0.88     29429\n",
      "\n",
      "    accuracy                           0.80     36036\n",
      "   macro avg       0.60      0.55      0.55     36036\n",
      "weighted avg       0.75      0.80      0.76     36036\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayanth C R\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for LogisticRegression: {'C': 0.1}\n",
      "\n",
      "Logistic Regression - Feature Extracted Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.06      0.10      6607\n",
      "           1       0.82      0.98      0.90     29429\n",
      "\n",
      "    accuracy                           0.81     36036\n",
      "   macro avg       0.63      0.52      0.50     36036\n",
      "weighted avg       0.75      0.81      0.75     36036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score, balanced_accuracy_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Paths for raw data\n",
    "raw_train_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Excel\\2. Merged Data\\train.csv\"\n",
    "raw_test_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Excel\\2. Merged Data\\test.csv\"\n",
    "\n",
    "# Paths for feature-extracted data\n",
    "X_train_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Excel\\5. Splitting\\X_train.csv\"\n",
    "y_train_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Excel\\5. Splitting\\y_train.csv\"\n",
    "X_test_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Excel\\5. Splitting\\X_test.csv\"\n",
    "y_test_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Excel\\5. Splitting\\y_test.csv\"\n",
    "\n",
    "# Load raw data\n",
    "def load_raw_data():\n",
    "    train_df = pd.read_csv(raw_train_path)\n",
    "    test_df = pd.read_csv(raw_test_path)\n",
    "    \n",
    "    X_train = train_df.iloc[:, :-1]\n",
    "    y_train = train_df.iloc[:, -1]\n",
    "    X_test = test_df.iloc[:, :-1]\n",
    "    y_test = test_df.iloc[:, -1]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Load feature-extracted data\n",
    "def load_feature_data():\n",
    "    X_train = pd.read_csv(X_train_path)\n",
    "    y_train = pd.read_csv(y_train_path).values.ravel()\n",
    "    X_test = pd.read_csv(X_test_path)\n",
    "    y_test = pd.read_csv(y_test_path).values.ravel()\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Standardize data\n",
    "def preprocess_data(X_train, X_test):\n",
    "    X_test = X_test[X_train.columns]  # Ensure same columns and order\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Hyperparameter tuning for traditional models\n",
    "def tune_hyperparameters(model, param_grid, X_train, y_train):\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best parameters for {model.__class__.__name__}: {grid_search.best_params_}\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# CNN model function for tuning\n",
    "def build_cnn_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=hp.Int('filters', min_value=16, max_value=128, step=16), kernel_size=3, activation='relu', input_shape=(X_train_raw.shape[1], 1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=hp.Int('units', min_value=32, max_value=256, step=32), activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', [0.01, 0.001, 0.0001])), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to train and evaluate models\n",
    "def train_and_evaluate_models(X_train, y_train, X_test, y_test, dataset_type=\"Feature Extracted\"):\n",
    "    models = {\n",
    "        \"Decision Tree\": (DecisionTreeClassifier(), {'max_depth': [5, 10, 20]}),\n",
    "        \"Random Forest\": (RandomForestClassifier(), {'n_estimators': [50, 100, 200]}),\n",
    "        \"KNN\": (KNeighborsClassifier(), {'n_neighbors': [3, 5, 7]}),\n",
    "        \"Logistic Regression\": (LogisticRegression(), {'C': [0.1, 1, 10]}),\n",
    "        \"SVM (Linear)\": (SVC(kernel='linear', probability=True), {'C': [0.1, 1, 10]}),\n",
    "        \"SVM (RBF)\": (SVC(kernel='rbf', probability=True), {'C': [0.1, 1, 10]}),\n",
    "        \"ANN (ReLU)\": (MLPClassifier(max_iter=500), {'hidden_layer_sizes': [(50,), (100,), (100, 50)]})\n",
    "    }\n",
    "    \n",
    "    for name, (model, params) in models.items():\n",
    "        best_model = tune_hyperparameters(model, params, X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        print(f\"\\n{name} - {dataset_type} Data\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Run for Feature Extracted Data\n",
    "X_train, y_train, X_test, y_test = load_feature_data()\n",
    "X_train, X_test = preprocess_data(X_train, X_test)\n",
    "train_and_evaluate_models(X_train, y_train, X_test, y_test, dataset_type=\"Feature Extracted\")\n",
    "\n",
    "# Run for Raw Data (CNN Only)\n",
    "X_train_raw, y_train_raw, X_test_raw, y_test_raw = load_raw_data()\n",
    "X_train_raw, X_test_raw = preprocess_data(X_train_raw, X_test_raw)\n",
    "X_train_raw = X_train_raw.reshape((X_train_raw.shape[0], X_train_raw.shape[1], 1))\n",
    "X_test_raw = X_test_raw.reshape((X_test_raw.shape[0], X_test_raw.shape[1], 1))\n",
    "\n",
    "tuner = kt.RandomSearch(build_cnn_model, objective='val_accuracy', max_trials=5, directory='cnn_tuning')\n",
    "tuner.search(X_train_raw, y_train_raw, epochs=10, validation_split=0.2)\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best CNN Hyperparameters: Filters: {best_hps.get('filters')}, Units: {best_hps.get('units')}, Learning Rate: {best_hps.get('learning_rate')}\")\n",
    "\n",
    "print(\"ðŸš€ Model training and evaluation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eac692-9592-4a38-9c7c-84e0fadd50d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
