{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dea7c2b-f84f-4280-874a-b2973f3dfc72",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'CinC/Training/tr03-0005/tr03-0005-arousal.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m path1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCinC/Training/tr03-0005/tr03-0005-arousal.mat\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;66;03m#change the folder path accordingly\u001b[39;00m\n\u001b[0;32m     32\u001b[0m signal_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCinC/Training/tr03-0005/tr03-0005.mat\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 34\u001b[0m stages \u001b[38;5;241m=\u001b[39m \u001b[43mimport_stages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m ecg \u001b[38;5;241m=\u001b[39m import_signals(signal_file)\n\u001b[0;32m     37\u001b[0m stages\u001b[38;5;241m.\u001b[39mhead() \u001b[38;5;66;03m#here you can see how the labels are given in a categorical manner. \u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m, in \u001b[0;36mimport_stages\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimport_stages\u001b[39m(file_name): \u001b[38;5;66;03m# target\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     wake \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39marray(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep_stages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwake\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     23\u001b[0m     n1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39marray(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep_stages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonrem1\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'CinC/Training/tr03-0005/tr03-0005-arousal.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def import_signals(file_name): # feature\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns = ['ecg'])\n",
    "    return ecg\n",
    "\n",
    "def import_stages(file_name): # target\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis = 1), columns = ['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "path1='CinC/Training/tr03-0005/tr03-0005-arousal.mat' #change the folder path accordingly\n",
    "signal_file = 'CinC/Training/tr03-0005/tr03-0005.mat'\n",
    "\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "stages.head() #here you can see how the labels are given in a categorical manner. \n",
    "\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1) #label binarization happens here.\n",
    "stages =stages[['label']]\n",
    "\n",
    "data = pd.concat([ecg, stages], axis = 1)\n",
    "data.head() #this is the finale dataframe with ecg signal and corresponding class labels\n",
    "\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency = 200, frame_length = 30, frame_stride = 30,\n",
    "                                         filter=lambda x: np.ones((x,)),zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency = 200, frame_length = 30, frame_stride = 30,\n",
    "                                         filter=lambda x: np.ones((x,)),zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 40% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "\n",
    "stage_labels_new\n",
    "\n",
    "stage_labels_new['label'].value_counts()\n",
    "\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis = 1)\n",
    "new_data\n",
    "\n",
    "new_data.to_csv('folder_path', sep = ',', index = False, header = True)\n",
    "\n",
    "## new_data is the processed and segmented file for one record, \n",
    "##Each row of the dataframe is ECG signal of 6000 samples and the last row is corresponding class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c719e8b0-2beb-4886-8100-42e3e7a5319d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:31: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:31: SyntaxWarning: invalid escape sequence '\\A'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\A'\n",
      "C:\\Users\\Jayanth C R\\AppData\\Local\\Temp\\ipykernel_21264\\468850548.py:31: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  path1=\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\\tr03-0394-arousal.mat\" #change the folder path accordingly\n",
      "C:\\Users\\Jayanth C R\\AppData\\Local\\Temp\\ipykernel_21264\\468850548.py:32: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  signal_file = \"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\\tr03-0394-arousal.mat\"\n",
      "C:\\Users\\Jayanth C R\\AppData\\Local\\Temp\\ipykernel_21264\\468850548.py:31: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  path1=\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\\tr03-0394-arousal.mat\" #change the folder path accordingly\n",
      "C:\\Users\\Jayanth C R\\AppData\\Local\\Temp\\ipykernel_21264\\468850548.py:32: SyntaxWarning: invalid escape sequence '\\A'\n",
      "  signal_file = \"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\\tr03-0394-arousal.mat\"\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Unable to synchronously open file (unable to open file: name = 'D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training!-70!-50\tr03-0394\tr03-0394-arousal.mat', errno = 22, error message = 'Invalid argument', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m path1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAmrita\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSem-4\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMachine Learning Lab\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEnd Sem Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;130;01m\\41\u001b[39;00m\u001b[38;5;124m-70\u001b[39m\u001b[38;5;130;01m\\41\u001b[39;00m\u001b[38;5;124m-50\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mr03-0394\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mr03-0394-arousal.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m#change the folder path accordingly\u001b[39;00m\n\u001b[0;32m     32\u001b[0m signal_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAmrita\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSem-4\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMachine Learning Lab\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEnd Sem Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;130;01m\\41\u001b[39;00m\u001b[38;5;124m-70\u001b[39m\u001b[38;5;130;01m\\41\u001b[39;00m\u001b[38;5;124m-50\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mr03-0394\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mr03-0394-arousal.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 34\u001b[0m stages \u001b[38;5;241m=\u001b[39m \u001b[43mimport_stages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m ecg \u001b[38;5;241m=\u001b[39m import_signals(signal_file)\n\u001b[0;32m     37\u001b[0m stages\u001b[38;5;241m.\u001b[39mhead() \u001b[38;5;66;03m#here you can see how the labels are given in a categorical manner. \u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m, in \u001b[0;36mimport_stages\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimport_stages\u001b[39m(file_name): \u001b[38;5;66;03m# target\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     wake \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39marray(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep_stages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwake\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     23\u001b[0m     n1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39marray(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep_stages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonrem1\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Unable to synchronously open file (unable to open file: name = 'D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training!-70!-50\tr03-0394\tr03-0394-arousal.mat', errno = 22, error message = 'Invalid argument', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def import_signals(file_name): # feature\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns = ['ecg'])\n",
    "    return ecg\n",
    "\n",
    "def import_stages(file_name): # target\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis = 1), columns = ['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "path1=\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\\tr03-0394-arousal.mat\" #change the folder path accordingly\n",
    "signal_file = \"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\\tr03-0394-arousal.mat\"\n",
    "\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "stages.head() #here you can see how the labels are given in a categorical manner. \n",
    "\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1) #label binarization happens here.\n",
    "stages =stages[['label']]\n",
    "\n",
    "data = pd.concat([ecg, stages], axis = 1)\n",
    "data.head() #this is the finale dataframe with ecg signal and corresponding class labels\n",
    "\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency = 200, frame_length = 30, frame_stride = 30,\n",
    "                                         filter=lambda x: np.ones((x,)),zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency = 200, frame_length = 30, frame_stride = 30,\n",
    "                                         filter=lambda x: np.ones((x,)),zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 40% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "\n",
    "stage_labels_new\n",
    "\n",
    "stage_labels_new['label'].value_counts()\n",
    "\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis = 1)\n",
    "new_data\n",
    "\n",
    "new_data.to_csv('folder_path', sep = ',', index = False, header = True)\n",
    "\n",
    "## new_data is the processed and segmented file for one record, \n",
    "##Each row of the dataframe is ECG signal of 6000 samples and the last row is corresponding class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0db4d14f-c1ea-4534-b8c7-caf82f6773af",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'D:\\sem 4\\ML project\\data\\Training\\1-40\\1-10\\tr03-0078\\tr03-0078-arousal.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m signal_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtr03-0078.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Import data\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m stages \u001b[38;5;241m=\u001b[39m \u001b[43mimport_stages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m ecg \u001b[38;5;241m=\u001b[39m import_signals(signal_file)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Display the first few rows of stages\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 23\u001b[0m, in \u001b[0;36mimport_stages\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimport_stages\u001b[39m(file_name):\n\u001b[1;32m---> 23\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     wake \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39marray(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep_stages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwake\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     25\u001b[0m     n1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39marray(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep_stages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonrem1\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'D:\\sem 4\\ML project\\data\\Training\\1-40\\1-10\\tr03-0078\\tr03-0078-arousal.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\sem 4\\ML project\\data\\Training\\1-40\\1-10\\tr03-0078\"\n",
    "path1 = os.path.join(base_path, \"tr03-0078-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0078.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0078.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21ae7a74-c87a-4df3-bc3d-a7141147478a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Please use HDF reader for matlab v7.3 files, e.g. h5py",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Import data\u001b[39;00m\n\u001b[0;32m     45\u001b[0m stages \u001b[38;5;241m=\u001b[39m import_stages(path1)\n\u001b[1;32m---> 46\u001b[0m ecg \u001b[38;5;241m=\u001b[39m \u001b[43mimport_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Display the initial data\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStages Head:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m, in \u001b[0;36mimport_signals\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimport_signals\u001b[39m(file_name):  \u001b[38;5;66;03m# feature\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     signal \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     18\u001b[0m     ecg \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(signal[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mecg\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ecg\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:234\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, spmatrix, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m variable_names \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvariable_names\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 234\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmat_reader_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m MR\u001b[38;5;241m.\u001b[39mget_variables(variable_names)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spmatrix:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\scipy\\io\\matlab\\_mio.py:80\u001b[0m, in \u001b[0;36mmat_reader_factory\u001b[1;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m MatFile5Reader(byte_stream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), file_opened\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mjv \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease use HDF reader for matlab v7.3 \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     81\u001b[0m                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiles, e.g. h5py\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDid not recognize version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmjv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Please use HDF reader for matlab v7.3 files, e.g. h5py"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import ECG signals from .mat file\n",
    "def import_signals(file_name):  # feature\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import sleep stages from .mat file\n",
    "def import_stages(file_name):  # target\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(\n",
    "        np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "        columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined']\n",
    "    )\n",
    "    return stages\n",
    "\n",
    "# Specify file paths\n",
    "path1 = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\\tr03-0394-arousal.mat\"\n",
    "signal_file = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\\tr03-0394-arousal.mat\"\n",
    "\n",
    "# Verify the file paths\n",
    "if not os.path.exists(path1) or not os.path.exists(signal_file):\n",
    "    raise FileNotFoundError(\"Specified file path does not exist. Check the file path.\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the initial data\n",
    "print(\"Stages Head:\")\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG data and stages into one DataFrame\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(\"Combined Data Head:\")\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG signals\n",
    "ecg_seg = speechpy.processing.stack_frames(\n",
    "    data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "    filter=lambda x: np.ones((x,)), zero_padding=True\n",
    ")\n",
    "stage_seg = speechpy.processing.stack_frames(\n",
    "    data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "    filter=lambda x: np.ones((x,)), zero_padding=True\n",
    ")\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify stage segments\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # At least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new DataFrame for segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "\n",
    "# Combine ECG segments with their corresponding labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Display processed data\n",
    "print(\"Processed Data Head:\")\n",
    "print(new_data.head())\n",
    "\n",
    "# Write the processed data to a CSV file\n",
    "output_file = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Processed_Data.csv\"\n",
    "new_data.to_csv(output_file, sep=',', index=False, header=True)\n",
    "print(f\"Processed data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9168adf-fb64-4540-afb1-443a3dc322e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to synchronously open object (object 'val' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Import data\u001b[39;00m\n\u001b[0;32m     44\u001b[0m stages \u001b[38;5;241m=\u001b[39m import_stages(path1)\n\u001b[1;32m---> 45\u001b[0m ecg \u001b[38;5;241m=\u001b[39m \u001b[43mimport_signals\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Display the initial data\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStages Head:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 16\u001b[0m, in \u001b[0;36mimport_signals\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimport_signals\u001b[39m(file_name):  \u001b[38;5;66;03m# feature\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m h5py\u001b[38;5;241m.\u001b[39mFile(file_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;66;03m# Adjust the key to access your dataset properly\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m         signal \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[:]\n\u001b[0;32m     17\u001b[0m     ecg \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(signal[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mecg\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ecg\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\group.py:357\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[1;32m--> 357\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5o.pyx:257\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Unable to synchronously open object (object 'val' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import os\n",
    "import biosppy as bp\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "import speechpy\n",
    "\n",
    "# Function to import ECG signals from .mat file using h5py\n",
    "def import_signals(file_name):  # feature\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        # Adjust the key to access your dataset properly\n",
    "        signal = f['val'][:]\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import sleep stages from .mat file\n",
    "def import_stages(file_name):  # target\n",
    "    with h5py.File(file_name, 'r') as f:\n",
    "        wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "        n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "        n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "        n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "        rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "        undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(\n",
    "        np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "        columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined']\n",
    "    )\n",
    "    return stages\n",
    "\n",
    "# Specify file paths\n",
    "path1 = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\\tr03-0394-arousal.mat\"\n",
    "signal_file = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\\tr03-0394-arousal.mat\"\n",
    "\n",
    "# Verify the file paths\n",
    "if not os.path.exists(path1) or not os.path.exists(signal_file):\n",
    "    raise FileNotFoundError(\"Specified file path does not exist. Check the file path.\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the initial data\n",
    "print(\"Stages Head:\")\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG data and stages into one DataFrame\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(\"Combined Data Head:\")\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG signals\n",
    "ecg_seg = speechpy.processing.stack_frames(\n",
    "    data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "    filter=lambda x: np.ones((x,)), zero_padding=True\n",
    ")\n",
    "stage_seg = speechpy.processing.stack_frames(\n",
    "    data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "    filter=lambda x: np.ones((x,)), zero_padding=True\n",
    ")\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify stage segments\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # At least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new DataFrame for segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "\n",
    "# Combine ECG segments with their corresponding labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Display processed data\n",
    "print(\"Processed Data Head:\")\n",
    "print(new_data.head())\n",
    "\n",
    "# Write the processed data to a CSV file\n",
    "output_file = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Processed_Data.csv\"\n",
    "new_data.to_csv(output_file, sep=',', index=False, header=True)\n",
    "print(f\"Processed data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c66afc52-8f41-43e0-877b-e60947b51470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  -46      0\n",
      "1   -2      0\n",
      "2  -13      0\n",
      "3  -44      0\n",
      "4  -19      0\n",
      "868 5209000 6000 6000.0\n",
      "868 5209000 6000 6000.0\n",
      "label\n",
      "1    758\n",
      "0    110\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\\processed_ecg_data_tr03-0394.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\"\n",
    "path1 = os.path.join(base_path, \"tr03-0394-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0394.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0394.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f17d48-bab3-41b7-965a-9c6e45d13487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0    5      0\n",
      "1   38      0\n",
      "2   32      0\n",
      "3   35      0\n",
      "4   27      0\n",
      "865 5196000 6000 6000.0\n",
      "865 5196000 6000 6000.0\n",
      "label\n",
      "1    738\n",
      "0    127\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0396\\processed_ecg_data_tr03-0396.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0396\"\n",
    "path1 = os.path.join(base_path, \"tr03-0396-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0396.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0396.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "590fc119-d3cd-4447-8a36-fb058af599ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0    7      0\n",
      "1   -3      0\n",
      "2   34      0\n",
      "3   54      0\n",
      "4   -7      0\n",
      "738 4432000 6000 6000.0\n",
      "738 4432000 6000 6000.0\n",
      "label\n",
      "1    431\n",
      "0    307\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0401\\processed_ecg_data_tr03-0401.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0401\"\n",
    "path1 = os.path.join(base_path, \"tr03-0401-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0401.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0401.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e0a69e8-9c1c-4bc9-b172-8bfaf8a07146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   75      0\n",
      "1  -53      0\n",
      "2 -113      0\n",
      "3   24      0\n",
      "4   41      0\n",
      "912 5474000 6000 6000.0\n",
      "912 5474000 6000 6000.0\n",
      "label\n",
      "1    855\n",
      "0     57\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0402\\processed_ecg_data_tr03-0402.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0402\"\n",
    "path1 = os.path.join(base_path, \"tr03-0402-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0402.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0402.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a91bf8f-c7c2-4f7f-8207-d8fa285cd55c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\\tr03-0411-arousal.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m signal_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtr03-0411.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Import data\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m stages \u001b[38;5;241m=\u001b[39m \u001b[43mimport_stages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m ecg \u001b[38;5;241m=\u001b[39m import_signals(signal_file)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Display the first few rows of stages\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 23\u001b[0m, in \u001b[0;36mimport_stages\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimport_stages\u001b[39m(file_name):\n\u001b[1;32m---> 23\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     wake \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39marray(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep_stages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwake\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     25\u001b[0m     n1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39marray(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep_stages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonrem1\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\\tr03-0411-arousal.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0394\"\n",
    "path1 = os.path.join(base_path, \"tr03-0411-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0411.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0411.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "592a1f1b-e3da-47df-8a6c-07c57036b30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   -9      0\n",
      "1  158      0\n",
      "2  154      0\n",
      "3  149      0\n",
      "4  109      0\n",
      "954 5726000 6000 6000.0\n",
      "954 5726000 6000 6000.0\n",
      "label\n",
      "1    800\n",
      "0    154\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0411\\processed_ecg_data_tr03-0411.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0411\"\n",
    "path1 = os.path.join(base_path, \"tr03-0411-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0411.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0411.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "928469b7-bae6-4b63-a14c-dfd2b1d9c662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   76      0\n",
      "1   66      0\n",
      "2   47      0\n",
      "3   49      0\n",
      "4   38      0\n",
      "1049 6299000 6000 6000.0\n",
      "1049 6299000 6000 6000.0\n",
      "label\n",
      "1    961\n",
      "0     88\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0413\\processed_ecg_data_tr03-0413.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0413\"\n",
    "path1 = os.path.join(base_path, \"tr03-0413-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0413.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0413.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40491c0f-a84f-4ff9-b0c6-b47c6cb3bade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "    ecg  label\n",
      "0  -540      0\n",
      "1   953      0\n",
      "2  -127      0\n",
      "3 -1073      0\n",
      "4   688      0\n",
      "975 5853000 6000 6000.0\n",
      "975 5853000 6000 6000.0\n",
      "label\n",
      "1    721\n",
      "0    254\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0418\\processed_ecg_data_tr03-0418.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0418\"\n",
    "path1 = os.path.join(base_path, \"tr03-0418-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0418.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0418.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3964e05-9ac6-40aa-9627-279bad4917cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  -32      0\n",
      "1  -83      0\n",
      "2    7      0\n",
      "3  273      0\n",
      "4  596      0\n",
      "964 5786000 6000 6000.0\n",
      "964 5786000 6000 6000.0\n",
      "label\n",
      "1    653\n",
      "0    311\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0426\\processed_ecg_data_tr03-0426.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0426\"\n",
    "path1 = os.path.join(base_path, \"tr03-0426-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0426.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0426.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "121ccec8-90b8-455c-92fb-d9f4a3d77d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   55      0\n",
      "1    1      0\n",
      "2  -23      0\n",
      "3   10      0\n",
      "4   36      0\n",
      "1013 6082000 6000 6000.0\n",
      "1013 6082000 6000 6000.0\n",
      "label\n",
      "1    600\n",
      "0    413\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0428\\processed_ecg_data_tr03-0428.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0428\"\n",
    "path1 = os.path.join(base_path, \"tr03-0428-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0428.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0428.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53cf88c3-c5b0-44af-b6ba-aac4ad5fd2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   28      0\n",
      "1  136      0\n",
      "2  108      0\n",
      "3  110      0\n",
      "4   93      0\n",
      "1045 6273000 6000 6000.0\n",
      "1045 6273000 6000 6000.0\n",
      "label\n",
      "1    887\n",
      "0    158\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0434\\processed_ecg_data_tr03-0434.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\41-50\\tr03-0434\"\n",
    "path1 = os.path.join(base_path, \"tr03-0434-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0434.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0434.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34e2df64-d9b6-41ce-a0a6-92e91717b1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  125      0\n",
      "1  -21      0\n",
      "2   36      0\n",
      "3   91      0\n",
      "4   86      0\n",
      "891 5349000 6000 6000.0\n",
      "891 5349000 6000 6000.0\n",
      "label\n",
      "0    509\n",
      "1    382\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0473\\processed_ecg_data_tr03-0473.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0473\"\n",
    "path1 = os.path.join(base_path, \"tr03-0473-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0473.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0473.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d65a5e28-b3f1-4ffe-8475-1b4c3d69f5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   55      0\n",
      "1  142      0\n",
      "2  110      0\n",
      "3  105      0\n",
      "4  129      0\n",
      "987 5926000 6000 6000.0\n",
      "987 5926000 6000 6000.0\n",
      "label\n",
      "1    959\n",
      "0     28\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0485\\processed_ecg_data_tr03-0485.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0485\"\n",
    "path1 = os.path.join(base_path, \"tr03-0485-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0485.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0485.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37629f72-c436-4288-adf5-88d8cf439241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  -14      0\n",
      "1   93      0\n",
      "2 -111      0\n",
      "3 -102      0\n",
      "4   91      0\n",
      "931 5592000 6000 6000.0\n",
      "931 5592000 6000 6000.0\n",
      "label\n",
      "1    696\n",
      "0    235\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0487\\processed_ecg_data_tr03-0487.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0487\"\n",
    "path1 = os.path.join(base_path, \"tr03-0487-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0487.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0487.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab937315-28e4-40af-992b-eed0f3d5512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   12      0\n",
      "1   -2      0\n",
      "2   -5      0\n",
      "3   -6      0\n",
      "4  -10      0\n",
      "908 5451000 6000 6000.0\n",
      "908 5451000 6000 6000.0\n",
      "label\n",
      "1    806\n",
      "0    102\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0494\\processed_ecg_data_tr03-0494.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0494\"\n",
    "path1 = os.path.join(base_path, \"tr03-0494-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0494.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0494.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6a2f13c-a1d7-4034-b645-1120a6005db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0 -498      0\n",
      "1  287      0\n",
      "2  191      0\n",
      "3   32      0\n",
      "4  167      0\n",
      "942 5654000 6000 6000.0\n",
      "942 5654000 6000 6000.0\n",
      "label\n",
      "1    788\n",
      "0    154\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0523\\processed_ecg_data_tr03-0523.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0523\"\n",
    "path1 = os.path.join(base_path, \"tr03-0523-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0523.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0523.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b67aa860-ef95-42f8-8b40-2f81b3015209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0    4      0\n",
      "1  -48      0\n",
      "2  -25      0\n",
      "3   -6      0\n",
      "4  -21      0\n",
      "900 5405000 6000 6000.0\n",
      "900 5405000 6000 6000.0\n",
      "label\n",
      "1    733\n",
      "0    167\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0532\\processed_ecg_data_tr03-0532.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0532\"\n",
    "path1 = os.path.join(base_path, \"tr03-0532-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0532.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0532.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0487ca0b-86ef-4096-b829-8caa8245d050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0 -791      0\n",
      "1  266      0\n",
      "2  124      0\n",
      "3  -68      0\n",
      "4   74      0\n",
      "849 5096000 6000 6000.0\n",
      "849 5096000 6000 6000.0\n",
      "label\n",
      "1    724\n",
      "0    125\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0536\\processed_ecg_data_tr03-0536.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0536\"\n",
    "path1 = os.path.join(base_path, \"tr03-0536-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0536.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0536.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b716462c-a2aa-42e2-b1fe-d0b8085e4614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  -28      0\n",
      "1  -34      0\n",
      "2  -35      0\n",
      "3  -16      0\n",
      "4    3      0\n",
      "1134 6806000 6000 6000.0\n",
      "1134 6806000 6000 6000.0\n",
      "label\n",
      "1    668\n",
      "0    466\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0541\\processed_ecg_data_tr03-0541.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0541\"\n",
    "path1 = os.path.join(base_path, \"tr03-0541-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0541.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0541.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d47e3bf-9348-4f49-a627-f29185778d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  -25      0\n",
      "1  -23      0\n",
      "2  -19      0\n",
      "3  -28      0\n",
      "4  -38      0\n",
      "990 5946000 6000 6000.0\n",
      "990 5946000 6000 6000.0\n",
      "label\n",
      "1    858\n",
      "0    132\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0560\\processed_ecg_data_tr03-0560.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0560\"\n",
    "path1 = os.path.join(base_path, \"tr03-0560-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0560.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0560.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ec37a41-1ce1-44eb-9978-fa980bba47c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   -5      0\n",
      "1   55      0\n",
      "2   43      0\n",
      "3   17      0\n",
      "4   13      0\n",
      "900 5406000 6000 6000.0\n",
      "900 5406000 6000 6000.0\n",
      "label\n",
      "1    777\n",
      "0    123\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0567\\processed_ecg_data_tr03-0567.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\51-60\\tr03-0567\"\n",
    "path1 = os.path.join(base_path, \"tr03-0567-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0567.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0567.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09f761f5-25ae-40a1-8b3d-168eb15c1970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   93      0\n",
      "1  -71      0\n",
      "2  -35      0\n",
      "3   29      0\n",
      "4   36      0\n",
      "925 5551000 6000 6000.0\n",
      "925 5551000 6000 6000.0\n",
      "label\n",
      "1    859\n",
      "0     66\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0584\\processed_ecg_data_tr03-0584.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0584\"\n",
    "path1 = os.path.join(base_path, \"tr03-0584-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0584.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0584.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20e0f54f-3d2a-4ef6-8c8d-f38383eb0733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0 -204      0\n",
      "1  -29      0\n",
      "2   36      0\n",
      "3 -281      0\n",
      "4 -170      0\n",
      "827 4963000 6000 6000.0\n",
      "827 4963000 6000 6000.0\n",
      "label\n",
      "1    719\n",
      "0    108\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0592\\processed_ecg_data_tr03-0592.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0592\"\n",
    "path1 = os.path.join(base_path, \"tr03-0592-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0592.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0592.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "745a32e7-aeab-4e2c-8064-7a0e63f359b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0    6      0\n",
      "1  -32      0\n",
      "2  -54      0\n",
      "3   -6      0\n",
      "4  -21      0\n",
      "889 5339000 6000 6000.0\n",
      "889 5339000 6000 6000.0\n",
      "label\n",
      "1    798\n",
      "0     91\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0618\\processed_ecg_data_tr03-0618.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0618\"\n",
    "path1 = os.path.join(base_path, \"tr03-0618-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0618.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0618.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e77762f9-8ffb-4974-b75b-845999f31f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0 -119      0\n",
      "1  326      0\n",
      "2  228      0\n",
      "3  178      0\n",
      "4  221      0\n",
      "811 4868000 6000 6000.0\n",
      "811 4868000 6000 6000.0\n",
      "label\n",
      "1    537\n",
      "0    274\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0623\\processed_ecg_data_tr03-0623.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0623\"\n",
    "path1 = os.path.join(base_path, \"tr03-0623-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0623.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0623.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ed124b2-c9de-4558-bd29-93b7583bebf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "    ecg  label\n",
      "0  1251      0\n",
      "1  2426      0\n",
      "2  1745      0\n",
      "3  1562      0\n",
      "4  2110      0\n",
      "826 4960000 6000 6000.0\n",
      "826 4960000 6000 6000.0\n",
      "label\n",
      "1    644\n",
      "0    182\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0645\\processed_ecg_data_tr03-0645.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0645\"\n",
    "path1 = os.path.join(base_path, \"tr03-0645-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0645.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0645.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "660cf3a2-b4eb-48d4-ac52-965feb7111a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   92      0\n",
      "1  174      0\n",
      "2  129      0\n",
      "3  101      0\n",
      "4  132      0\n",
      "969 5816000 6000 6000.0\n",
      "969 5816000 6000 6000.0\n",
      "label\n",
      "1    863\n",
      "0    106\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0672\\processed_ecg_data_tr03-0672.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0672\"\n",
    "path1 = os.path.join(base_path, \"tr03-0672-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0672.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0672.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fe5fefc-532b-4cde-818b-cf2da6d3f6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  -74      0\n",
      "1   42      0\n",
      "2   62      0\n",
      "3   30      0\n",
      "4   45      0\n",
      "978 5870000 6000 6000.0\n",
      "978 5870000 6000 6000.0\n",
      "label\n",
      "1    782\n",
      "0    196\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0674\\processed_ecg_data_tr03-0674.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0674\"\n",
    "path1 = os.path.join(base_path, \"tr03-0674-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0674.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0674.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d7ca7e3-ba19-4128-8baf-32db55451366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   87      0\n",
      "1  148      0\n",
      "2  147      0\n",
      "3  140      0\n",
      "4  140      0\n",
      "889 5337000 6000 6000.0\n",
      "889 5337000 6000 6000.0\n",
      "label\n",
      "1    601\n",
      "0    288\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0678\\processed_ecg_data_tr03-0678.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0678\"\n",
    "path1 = os.path.join(base_path, \"tr03-0678-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0678.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0678.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b865016-6bf6-4e07-a7d1-0741548d5836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  -28      0\n",
      "1   27      0\n",
      "2    9      0\n",
      "3  -12      0\n",
      "4    6      0\n",
      "946 5678000 6000 6000.0\n",
      "946 5678000 6000 6000.0\n",
      "label\n",
      "1    749\n",
      "0    197\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0686\\processed_ecg_data_tr03-0686.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0686\"\n",
    "path1 = os.path.join(base_path, \"tr03-0686-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0686.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0686.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba9f1cde-428e-4e0e-834e-856cdc13ae34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  -17      0\n",
      "1  112      0\n",
      "2   98      0\n",
      "3   30      0\n",
      "4    8      0\n",
      "964 5788000 6000 6000.0\n",
      "964 5788000 6000 6000.0\n",
      "label\n",
      "1    524\n",
      "0    440\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0697\\processed_ecg_data_tr03-0697.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\41-70\\61-70\\tr03-0697\"\n",
    "path1 = os.path.join(base_path, \"tr03-0697-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0697.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0697.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fa2573b-f124-4f40-86f6-aeeff2f63e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  -14      0\n",
      "1  -31      0\n",
      "2  -37      0\n",
      "3  -53      0\n",
      "4  -57      0\n",
      "883 5301000 6000 6000.0\n",
      "883 5301000 6000 6000.0\n",
      "label\n",
      "1    788\n",
      "0     95\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0785\\processed_ecg_data_tr03-0785.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0785\"\n",
    "path1 = os.path.join(base_path, \"tr03-0785-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0785.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0785.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82667073-c66e-4310-99f8-59e696930b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  183      0\n",
      "1  464      0\n",
      "2  601      0\n",
      "3  715      0\n",
      "4  520      0\n",
      "1019 6115000 6000 6000.0\n",
      "1019 6115000 6000 6000.0\n",
      "label\n",
      "1    841\n",
      "0    178\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0792\\processed_ecg_data_tr03-0792.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0792\"\n",
    "path1 = os.path.join(base_path, \"tr03-0792-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0792.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0792.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b35faefc-f329-4803-821f-83e7250cc6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  -14      0\n",
      "1  -31      0\n",
      "2  -37      0\n",
      "3  -53      0\n",
      "4  -57      0\n",
      "883 5301000 6000 6000.0\n",
      "883 5301000 6000 6000.0\n",
      "label\n",
      "1    788\n",
      "0     95\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0785\\processed_ecg_data_tr03-0785.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0785\"\n",
    "path1 = os.path.join(base_path, \"tr03-0785-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0785.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0785.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f872ef9f-1083-4df7-9dac-7566794baa75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0    5      0\n",
      "1   27      0\n",
      "2   29      0\n",
      "3   25      0\n",
      "4   19      0\n",
      "882 5293000 6000 6000.0\n",
      "882 5293000 6000 6000.0\n",
      "label\n",
      "1    605\n",
      "0    277\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0793\\processed_ecg_data_tr03-0793.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0793\"\n",
    "path1 = os.path.join(base_path, \"tr03-0793-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0793.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0793.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47ca7d02-b1d3-4730-a0e4-aee8abe80796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   34      0\n",
      "1  -22      0\n",
      "2   57      0\n",
      "3   39      0\n",
      "4  -39      0\n",
      "784 4708000 6000 6000.0\n",
      "784 4708000 6000 6000.0\n",
      "label\n",
      "1    580\n",
      "0    204\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0796\\processed_ecg_data_tr03-0796.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0796\"\n",
    "path1 = os.path.join(base_path, \"tr03-0796-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0796.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0796.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f02b69fd-b509-4440-bd11-be222495b2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   44      0\n",
      "1   93      0\n",
      "2   76      0\n",
      "3   53      0\n",
      "4   56      0\n",
      "971 5830000 6000 6000.0\n",
      "971 5830000 6000 6000.0\n",
      "label\n",
      "1    673\n",
      "0    298\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0802\\processed_ecg_data_tr03-0802.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0802\"\n",
    "path1 = os.path.join(base_path, \"tr03-0802-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0802.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0802.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9315470-81a7-4d09-8de4-5c9c0b688cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   45      0\n",
      "1   10      0\n",
      "2  -18      0\n",
      "3   54      0\n",
      "4  107      0\n",
      "948 5691000 6000 6000.0\n",
      "948 5691000 6000 6000.0\n",
      "label\n",
      "1    834\n",
      "0    114\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0816\\processed_ecg_data_tr03-0816.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0816\"\n",
    "path1 = os.path.join(base_path, \"tr03-0816-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0816.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0816.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a51581b6-a431-4956-9142-8becb16826c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "    ecg  label\n",
      "0   554      0\n",
      "1    31      0\n",
      "2  -568      0\n",
      "3   359      0\n",
      "4  1081      0\n",
      "933 5599000 6000 6000.0\n",
      "933 5599000 6000 6000.0\n",
      "label\n",
      "1    803\n",
      "0    130\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0862\\processed_ecg_data_tr03-0862.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0862\"\n",
    "path1 = os.path.join(base_path, \"tr03-0862-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0862.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0862.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73e83692-d3e1-41e7-90a5-8090df6478a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   -5      0\n",
      "1  -18      0\n",
      "2  -29      0\n",
      "3  -12      0\n",
      "4   14      0\n",
      "830 4986000 6000 6000.0\n",
      "830 4986000 6000 6000.0\n",
      "label\n",
      "1    556\n",
      "0    274\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0863\\processed_ecg_data_tr03-0863.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0863\"\n",
    "path1 = os.path.join(base_path, \"tr03-0863-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0863.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0863.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "250a4812-d925-4b90-acde-c6ac8be49193",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0867\\tr03-0867-arousal.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m signal_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtr03-0867.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Import data\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m stages \u001b[38;5;241m=\u001b[39m \u001b[43mimport_stages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m ecg \u001b[38;5;241m=\u001b[39m import_signals(signal_file)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Display the first few rows of stages\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[50], line 23\u001b[0m, in \u001b[0;36mimport_stages\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimport_stages\u001b[39m(file_name):\n\u001b[1;32m---> 23\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     wake \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39marray(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep_stages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwake\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     25\u001b[0m     n1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39marray(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep_stages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonrem1\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0867\\tr03-0867-arousal.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0867\"\n",
    "path1 = os.path.join(base_path, \"tr03-0867-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0867.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0867.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a4c4a6f-be80-482e-978d-91ce7f5419f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0 -117      0\n",
      "1   20      0\n",
      "2   71      0\n",
      "3  196      0\n",
      "4   60      0\n",
      "1061 6368000 6000 6000.0\n",
      "1061 6368000 6000 6000.0\n",
      "label\n",
      "1    734\n",
      "0    327\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0876\\processed_ecg_data_tr03-0876.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0876\"\n",
    "path1 = os.path.join(base_path, \"tr03-0876-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0876.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0876.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2ee76df-d9cc-4c04-a588-bfdbdc8192a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   -1      0\n",
      "1   -1      0\n",
      "2  -26      0\n",
      "3  -68      0\n",
      "4  -64      0\n",
      "926 5558000 6000 6000.0\n",
      "926 5558000 6000 6000.0\n",
      "label\n",
      "1    827\n",
      "0     99\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0879\\processed_ecg_data_tr03-0879.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0879\"\n",
    "path1 = os.path.join(base_path, \"tr03-0879-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0879.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0879.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d521d670-5a5c-43c1-a585-719df155acf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  373      0\n",
      "1  185      0\n",
      "2 -169      0\n",
      "3 -136      0\n",
      "4  227      0\n",
      "995 5975000 6000 6000.0\n",
      "995 5975000 6000 6000.0\n",
      "label\n",
      "1    963\n",
      "0     32\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0885\\processed_ecg_data_tr03-0885.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0885\"\n",
    "path1 = os.path.join(base_path, \"tr03-0885-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0885.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0885.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6d2f22c-37d9-4ff0-8d2e-47ada9696a81",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0900\\tr03-0900-arousal.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m signal_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtr03-0900.mat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Import data\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m stages \u001b[38;5;241m=\u001b[39m \u001b[43mimport_stages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m ecg \u001b[38;5;241m=\u001b[39m import_signals(signal_file)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Display the first few rows of stages\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[54], line 23\u001b[0m, in \u001b[0;36mimport_stages\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimport_stages\u001b[39m(file_name):\n\u001b[1;32m---> 23\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     wake \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39marray(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep_stages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwake\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     25\u001b[0m     n1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39marray(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msleep_stages\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonrem1\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0900\\tr03-0900-arousal.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\81-90\\tr03-0900\"\n",
    "path1 = os.path.join(base_path, \"tr03-0900-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0900.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0900.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "16bc331f-b2a7-4743-bf92-1c5d368e46a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   90      0\n",
      "1 -117      0\n",
      "2  -42      0\n",
      "3  297      0\n",
      "4  -24      0\n",
      "1002 6016000 6000 6000.0\n",
      "1002 6016000 6000 6000.0\n",
      "label\n",
      "1    863\n",
      "0    139\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0900\\processed_ecg_data_tr03-0900.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0900\"\n",
    "path1 = os.path.join(base_path, \"tr03-0900-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0900.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0900.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98b4a758-5a8b-406c-b94c-972ded53ea32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  -84      0\n",
      "1  -23      0\n",
      "2   40      0\n",
      "3    6      0\n",
      "4  -45      0\n",
      "954 5729000 6000 6000.0\n",
      "954 5729000 6000 6000.0\n",
      "label\n",
      "1    907\n",
      "0     47\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0904\\processed_ecg_data_tr03-0904.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0904\"\n",
    "path1 = os.path.join(base_path, \"tr03-0904-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0904.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0904.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5504da9-86ef-4b74-bf4d-f735984c1499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "    ecg  label\n",
      "0   204      0\n",
      "1  1113      0\n",
      "2  -786      0\n",
      "3  -986      0\n",
      "4  1744      0\n",
      "859 5157000 6000 6000.0\n",
      "859 5157000 6000 6000.0\n",
      "label\n",
      "1    716\n",
      "0    143\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0906\\processed_ecg_data_tr03-0906.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0906\"\n",
    "path1 = os.path.join(base_path, \"tr03-0906-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0906.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0906.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c330c5a2-4804-4f88-a680-a2926527d999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   10      0\n",
      "1   -8      0\n",
      "2   -8      0\n",
      "3   -8      0\n",
      "4  -13      0\n",
      "881 5287000 6000 6000.0\n",
      "881 5287000 6000 6000.0\n",
      "label\n",
      "1    818\n",
      "0     63\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0907\\processed_ecg_data_tr03-0907.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0907\"\n",
    "path1 = os.path.join(base_path, \"tr03-0907-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0907.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0907.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ded322cb-5875-4f0a-b881-9d8ab842b30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  -77      0\n",
      "1 -136      0\n",
      "2  -82      0\n",
      "3   -8      0\n",
      "4  -74      0\n",
      "885 5316000 6000 6000.0\n",
      "885 5316000 6000 6000.0\n",
      "label\n",
      "1    711\n",
      "0    174\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0909\\processed_ecg_data_tr03-0909.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0909\"\n",
    "path1 = os.path.join(base_path, \"tr03-0909-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0909.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0909.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13a31f34-2c97-449d-b97b-4816ea6a75f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0  -78      0\n",
      "1  -40      0\n",
      "2  -65      0\n",
      "3  -90      0\n",
      "4  -79      0\n",
      "921 5532000 6000 6000.0\n",
      "921 5532000 6000 6000.0\n",
      "label\n",
      "1    790\n",
      "0    131\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0919\\processed_ecg_data_tr03-0919.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0919\"\n",
    "path1 = os.path.join(base_path, \"tr03-0919-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0919.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0919.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "544c8818-69e2-4dc4-8b5f-aa918cd13c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   -5      0\n",
      "1    4      0\n",
      "2   -4      0\n",
      "3  -20      0\n",
      "4    0      0\n",
      "1060 6361000 6000 6000.0\n",
      "1060 6361000 6000 6000.0\n",
      "label\n",
      "1    929\n",
      "0    131\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0921\\processed_ecg_data_tr03-0921.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0921\"\n",
    "path1 = os.path.join(base_path, \"tr03-0921-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0921.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0921.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "444f32a7-f8f1-4d44-bb50-df31bd5b2a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0 -312      0\n",
      "1 -820      0\n",
      "2 -738      0\n",
      "3 -531      0\n",
      "4 -532      0\n",
      "844 5068000 6000 6000.0\n",
      "844 5068000 6000 6000.0\n",
      "label\n",
      "1    610\n",
      "0    234\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0933\\processed_ecg_data_tr03-0933.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0933\"\n",
    "path1 = os.path.join(base_path, \"tr03-0933-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0933.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0933.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "819356e8-d745-435d-a4b1-eabcc922ca7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Wake  N1  N2  N3  REM  Undefined\n",
      "0     0   0   0   0    0          1\n",
      "1     0   0   0   0    0          1\n",
      "2     0   0   0   0    0          1\n",
      "3     0   0   0   0    0          1\n",
      "4     0   0   0   0    0          1\n",
      "   ecg  label\n",
      "0   24      0\n",
      "1  -56      0\n",
      "2  -29      0\n",
      "3  -18      0\n",
      "4  -28      0\n",
      "836 5022000 6000 6000.0\n",
      "836 5022000 6000 6000.0\n",
      "label\n",
      "1    746\n",
      "0     90\n",
      "Name: count, dtype: int64\n",
      "Processed data saved at: D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0940\\processed_ecg_data_tr03-0940.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.io\n",
    "import cv2\n",
    "import os\n",
    "import biosppy as bp\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import speechpy\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "import neurokit2 as nk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to import signals (features)\n",
    "def import_signals(file_name):\n",
    "    signal = scipy.io.loadmat(file_name)['val']\n",
    "    ecg = pd.DataFrame(signal[-1], columns=['ecg'])\n",
    "    return ecg\n",
    "\n",
    "# Function to import stages (targets)\n",
    "def import_stages(file_name):\n",
    "    f = h5py.File(file_name, 'r')\n",
    "    wake = np.transpose(np.array(f['data']['sleep_stages']['wake']))\n",
    "    n1 = np.transpose(np.array(f['data']['sleep_stages']['nonrem1']))\n",
    "    n2 = np.transpose(np.array(f['data']['sleep_stages']['nonrem2']))\n",
    "    n3 = np.transpose(np.array(f['data']['sleep_stages']['nonrem3']))\n",
    "    rem = np.transpose(np.array(f['data']['sleep_stages']['rem']))\n",
    "    undef = np.transpose(np.array(f['data']['sleep_stages']['undefined']))\n",
    "    stages = pd.DataFrame(np.concatenate((wake, n1, n2, n3, rem, undef), axis=1),\n",
    "                          columns=['Wake', 'N1', 'N2', 'N3', 'REM', 'Undefined'])\n",
    "    return stages\n",
    "\n",
    "# Updated file paths\n",
    "base_path = r\"D:\\Amrita\\Sem-4\\Machine Learning Lab\\End Sem Project\\Training\\71-100\\91-100\\tr03-0940\"\n",
    "path1 = os.path.join(base_path, \"tr03-0940-arousal.mat\")\n",
    "signal_file = os.path.join(base_path, \"tr03-0940.mat\")\n",
    "\n",
    "# Import data\n",
    "stages = import_stages(path1)\n",
    "ecg = import_signals(signal_file)\n",
    "\n",
    "# Display the first few rows of stages\n",
    "print(stages.head())\n",
    "\n",
    "# Label binarization\n",
    "stages['label'] = stages[['Wake', 'Undefined']].sum(axis=1).apply(lambda x: 0 if x > 0 else 1)\n",
    "stages = stages[['label']]\n",
    "\n",
    "# Combine ECG signals and stages into one dataframe\n",
    "data = pd.concat([ecg, stages], axis=1)\n",
    "print(data.head())\n",
    "\n",
    "# Segment ECG and stage data\n",
    "ecg_seg = speechpy.processing.stack_frames(data['ecg'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                           filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "stage_seg = speechpy.processing.stack_frames(data['label'], sampling_frequency=200, frame_length=30, frame_stride=30,\n",
    "                                             filter=lambda x: np.ones((x,)), zero_padding=True)\n",
    "ecg_seg = pd.DataFrame(ecg_seg.T)\n",
    "stage_seg = pd.DataFrame(stage_seg.T)\n",
    "\n",
    "# Classify columns based on the number of \"1\"s in each segment\n",
    "def classify_column(column):\n",
    "    one_count = (column == 1).sum()\n",
    "    if one_count >= 0.9 * len(column):  # Check if at least 90% of values are 1\n",
    "        return 1  # Class 1\n",
    "    else:\n",
    "        return 0  # Class 0\n",
    "\n",
    "stage_labels = stage_seg.apply(classify_column, axis=0)\n",
    "\n",
    "# Create a new dataframe for the segment labels\n",
    "stage_labels_new = pd.DataFrame({'label': stage_labels})\n",
    "print(stage_labels_new['label'].value_counts())\n",
    "\n",
    "# Combine segmented ECG and labels\n",
    "new_data = pd.concat([ecg_seg.T, stage_labels_new], axis=1)\n",
    "\n",
    "# Save the processed data\n",
    "output_path = os.path.join(base_path, \"processed_ecg_data_tr03-0940.csv\")\n",
    "new_data.to_csv(output_path, sep=',', index=False, header=True)\n",
    "\n",
    "print(f\"Processed data saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63444cb-cf9d-402f-9c61-d7ffd7acd455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
